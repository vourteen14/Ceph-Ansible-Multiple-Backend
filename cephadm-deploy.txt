#####################
# Node Minimal Spec #
#####################
Proc: 1 Core
Mem: 4G
Disk 1(OS): 24G(Min) /dev/sda
Disk 2(hdd): 5G(Min) /dev/sdb
Disk 3(ssd): 5G(Min) /dev/sdc
OS: Ubuntu 20.04

Hostname: ceph01,ceph02,ceph03
IP: 10.10.10.111, 10.10.10.112, 10.10.10.113
User: ubuntu
Pass: ubuntu

I'm using 3 node with same spec and /etc/hosts was modified mapping IP to hostname 

###############
# My Net Conf #
###############
NIC 1: 10.10.10.0/24

####################
# On All Ceph Node #
####################
$ sudo apt install chrony -y

$ nano /etc/chrony/chrony.conf >>
  ...
  pool 0.id.pool.ntp.org iburst
  pool 1.id.pool.ntp.org iburst
  pool 2.id.pool.ntp.org iburst
  pool 3.id.pool.ntp.org iburst

$ sudo systemctl restart chronyd

$ sudo apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common -y
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ echo "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -sc) stable" | sudo tee /etc/apt/sources.list.d/docker-ce.list
$ sudo apt update
$ sudo apt install docker-ce docker-ce-cli containerd.io -y
$ sudo systemctl enable --now docker

###################
# Do on CEPH01!!! #
###################
$ ssh-keygen -t rsa 
$ sudo apt install sshpass -y
$ for i in `seq 1 3`; do sshpass -p ubuntu ssh-copy-id -i /home/ubuntu/.ssh/id_rsa.pub ubuntu@ceph0$i; done

$ curl --silent --remote-name --location https://github.com/ceph/ceph/raw/quincy/src/cephadm/cephadm
$ chmod +x cephadm

$ sudo ./cephadm add-repo --release quincy
$ sudo ./cephadm install
$ sudo ./cephadm bootstrap --mon-ip 10.10.10.111

$ sudo ceph telemetry enable channel perf
$ sudo ceph telemetry on --license sharing-1-0

$ sudo ceph cephadm get-ssh-config > ssh_config
$ sudo ceph config-key get mgr/cephadm/ssh_identity_key > key
$ sudo chmod 600 key
$ ssh-keygen -y -f key > key.pub
$ for i in `seq 1 3`; do scp key.pub ubuntu@ceph0$i:/home/ubuntu; done

##########################
# SSHD Setup On All Node #
##########################
$ sudo nano /etc/ssh/sshd_config >>
  ...
  PermitRootLogin yes
$ sudo systemctl restart ssh sshd
$ cat key.pub | sudo tee -a /root/.ssh/authorized_keys

#############################################
# Add Host to Cluster do below on CEPH01!!! #
#############################################
$ sudo ceph orch host add ceph02 10.10.10.111 --labels _admin
$ sudo ceph orch host add ceph03 10.10.10.112 --labels _admin

############################################
# Add OSD to Cluster do below on CEPH01!!! #
############################################
$ ceph orch daemon add osd ceph01:data_devices=/dev/sdb,/dev/sdc
$ ceph orch daemon add osd ceph02:data_devices=/dev/sdb,/dev/sdc
$ ceph orch daemon add osd ceph03:data_devices=/dev/sdb,/dev/sdc

####################
## CEPH INIT DONE ##
####################

fallocate -l 2G test-file.img
rados put test-file.img test-file.img --pool=test-pool
ceph config set global osd_max_object_size 2G

rados -p test-pool ls
ceph osd map test-pool test-file.img

rados get test-file.img test-file.img --pool=test-pool
